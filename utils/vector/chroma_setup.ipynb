{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /home/ubuntu/.local/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: langchain-community in /home/ubuntu/.local/lib/python3.10/site-packages (0.2.11)\n",
      "Requirement already satisfied: pypdf in /home/ubuntu/.local/lib/python3.10/site-packages (4.3.1)\n",
      "Requirement already satisfied: openai in /home/ubuntu/.local/lib/python3.10/site-packages (1.40.0)\n",
      "Requirement already satisfied: chromadb in /home/ubuntu/.local/lib/python3.10/site-packages (0.5.5)\n",
      "Requirement already satisfied: tiktoken in /home/ubuntu/.local/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (0.1.98)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (0.2.28)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (3.10.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pypdf) (4.12.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (0.112.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (1.26.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (1.65.4)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (3.10.6)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (0.19.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (1.26.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (30.1.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (1.26.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (4.2.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (0.30.5)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (0.12.3)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from chromadb) (1.18.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken) (2024.7.24)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: packaging>=19.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Requirement already satisfied: pyproject_hooks in /home/ubuntu/.local/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.33.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/lib/python3/dist-packages (from kubernetes>=28.1.0->chromadb) (1.26.5)\n",
      "Requirement already satisfied: requests-oauthlib in /home/ubuntu/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: flatbuffers in /home/ubuntu/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: protobuf in /home/ubuntu/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.4)\n",
      "Requirement already satisfied: coloredlogs in /home/ubuntu/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: importlib-metadata<=8.0.0,>=6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.0.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.26.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.26.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
      "Requirement already satisfied: opentelemetry-proto==1.26.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.47b0 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.47b0 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.47b0 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.47b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/lib/python3/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (59.6.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ubuntu/.local/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.24.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/lib/python3/dist-packages (from typer>=0.9.0->chromadb) (8.0.3)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/ubuntu/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/ubuntu/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/ubuntu/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/.local/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.4.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (1.0.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.20-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tiktoken<1,>=0.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-openai) (1.40.0)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-openai) (0.2.28)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (2.8.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (0.1.98)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (24.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.5.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain-openai) (2.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ubuntu/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-openai) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.5)\n",
      "Installing collected packages: langchain-openai\n",
      "Successfully installed langchain-openai-0.1.20\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-community pypdf openai chromadb tiktoken\n",
    "%pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain dependencies\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader # Importing PDF loader from Langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # Importing text splitter from Langchain\n",
    "# from langchain.embeddings import OpenAIEmbeddings # Importing OpenAI embeddings from Langchain\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document # Importing Document schema from Langchain\n",
    "from langchain.vectorstores.chroma import Chroma # Importing Chroma vector store from Langchain\n",
    "from langchain.chat_models import ChatOpenAI # Import OpenAI LLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv # Importing dotenv to get API key from .env file\n",
    "import os # Importing os module for operating system functionalities\n",
    "import shutil # Importing shutil module for high-level file operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to your pdf files:\n",
    "DATA_PATH = \"./data/\"\n",
    "def load_documents():\n",
    "  \"\"\"\n",
    "  Load PDF documents from the specified directory using PyPDFDirectoryLoader.\n",
    "  Returns:\n",
    "  List of Document objects: Loaded PDF documents represented as Langchain\n",
    "                                                          Document objects.\n",
    "  \"\"\"\n",
    "  # Initialize PDF loader with specified directory\n",
    "  document_loader = PyPDFDirectoryLoader(DATA_PATH) \n",
    "  # Load PDF documents and return them as a list of Document objects\n",
    "  return document_loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Ski\n",
      "Boots\n",
      "TDBootz\n",
      "Special\n",
      "This\n",
      "guide\n",
      "explains\n",
      "the\n",
      "special\n",
      "consider ation\n",
      "for\n",
      "choosing\n",
      "TDBootz\n",
      "Special\n",
      "Ski\n",
      "boots.\n",
      "1.\n",
      "Understanding\n",
      "Ski\n",
      "Boot\n",
      "Components:\n",
      "Befor e\n",
      "delving\n",
      "int o\n",
      "selecting\n",
      "ski\n",
      "boots,\n",
      "it' s\n",
      "essential\n",
      "t o\n",
      "understand\n",
      "the\n",
      "v arious\n",
      "components\n",
      "that\n",
      "mak e\n",
      "up\n",
      "a\n",
      "ski\n",
      "boot:\n",
      "●\n",
      "Shell:\n",
      "The\n",
      "outer\n",
      "body\n",
      "of\n",
      "the\n",
      "boot,\n",
      "typically\n",
      "made\n",
      "of\n",
      "plastic,\n",
      "which\n",
      "pr o vides\n",
      "structur e\n",
      "and\n",
      "suppor t.\n",
      "●\n",
      "Liner:\n",
      "The\n",
      "inner\n",
      "la y er\n",
      "of\n",
      "the\n",
      "boot,\n",
      "usually\n",
      "made\n",
      "of\n",
      "foam,\n",
      "which\n",
      "pr o vides\n",
      "cushioning,\n",
      "insulation,\n",
      "and\n",
      "comfor t.\n",
      "●\n",
      "Buckles:\n",
      "Ski\n",
      "boots\n",
      "usually\n",
      "ha v e\n",
      "se v er al\n",
      "buckles\n",
      "or\n",
      "str aps\n",
      "t o\n",
      "secur e\n",
      "the\n",
      "boot\n",
      "tightly\n",
      "ar ound\n",
      "y our\n",
      "foot\n",
      "and\n",
      "leg.\n",
      "●\n",
      "Cuff:\n",
      "The\n",
      "upper\n",
      "par t\n",
      "of\n",
      "the\n",
      "boot\n",
      "that\n",
      "wr aps\n",
      "ar ound\n",
      "y our\n",
      "lower\n",
      "leg,\n",
      "pr o viding\n",
      "suppor t\n",
      "and\n",
      "tr ansmitting\n",
      "mo v ements\n",
      "t o\n",
      "the\n",
      "skis.\n",
      "●\n",
      "Sole:\n",
      "The\n",
      "bott om\n",
      "of\n",
      "the\n",
      "boot,\n",
      "which\n",
      "inter faces\n",
      "with\n",
      "the\n",
      "ski\n",
      "bindings.\n",
      "●\n",
      "Ski/W alk\n",
      "Mode:\n",
      "Many\n",
      "modern\n",
      "ski\n",
      "boots\n",
      "f eatur e\n",
      "a\n",
      "mechanism\n",
      "that\n",
      "allows\n",
      "y ou\n",
      "t o\n",
      "switch\n",
      "between\n",
      "a\n",
      "stiff,\n",
      "lock ed\n",
      "position\n",
      "for\n",
      "skiing\n",
      "and\n",
      "a\n",
      "mor e\n",
      "ﬂexible,\n",
      "walking-friendly\n",
      "position\n",
      "for\n",
      "off-slope\n",
      "mobility .\n",
      "●\n",
      "TDBootz\n",
      "ski\n",
      "boots\n",
      "also\n",
      "include\n",
      "a\n",
      "special\n",
      "component\n",
      "called\n",
      "Super-F a v ourite\n",
      "that\n",
      "mak es\n",
      "them\n",
      "mor e\n",
      "comfor table.\n",
      "2.\n",
      "Selecting\n",
      "the\n",
      "Right\n",
      "Ski\n",
      "Boot:\n",
      "Choosing\n",
      "the\n",
      "right\n",
      "ski\n",
      "boot\n",
      "inv olv es\n",
      "considering\n",
      "se v er al\n",
      "fact ors,\n",
      "including\n",
      "y our\n",
      "skiing\n",
      "ability ,\n",
      "foot\n",
      "shape,\n",
      "and\n",
      "intended\n",
      "use\n",
      "(e.g.,\n",
      "alpine\n",
      "skiing,\n",
      "back countr y\n",
      "skiing,\n",
      "fr eestyle\n",
      "skiing).\n",
      "Her e\n",
      "ar e\n",
      "some\n",
      "k e y\n",
      "consider ations:\n",
      "●\n",
      "Flex\n",
      "Rating:\n",
      "Ski\n",
      "boots\n",
      "come\n",
      "in\n",
      "v arious\n",
      "ﬂex\n",
      "r atings,\n",
      "which\n",
      "indicate\n",
      "their\n",
      "stiffness.\n",
      "Beginners\n",
      "typically\n",
      "beneﬁt\n",
      "fr om\n",
      "softer\n",
      "boots\n",
      "(lower\n",
      "ﬂex\n",
      "r atings)\n",
      "for\n",
      "easier\n",
      "contr ol,\n",
      "while\n",
      "adv anced\n",
      "skiers\n",
      "ma y\n",
      "pr ef er\n",
      "stiff er\n",
      "boots\n",
      "(higher\n",
      "ﬂex\n",
      "r atings)\n",
      "for\n",
      "better\n",
      "r esponsiv eness\n",
      "at\n",
      "high\n",
      "speeds\n",
      "and\n",
      "on\n",
      "challenging\n",
      "terr ain.\n",
      "●\n",
      "Last\n",
      "Width:\n",
      "The\n",
      "last\n",
      "width\n",
      "r ef ers\n",
      "t o\n",
      "the\n",
      "width\n",
      "of\n",
      "the\n",
      "boot' s\n",
      "for efoot\n",
      "ar ea.\n",
      "Boots\n",
      "come\n",
      "in\n",
      "diff er ent\n",
      "last\n",
      "widths\n",
      "t o\n",
      "accommodate\n",
      "v arious\n",
      "foot\n",
      "shapes.\n",
      "Narr ow\n",
      "lasts\n",
      "ar e\n",
      "suitable\n",
      "for\n",
      "slim\n",
      "f eet,\n",
      "while\n",
      "wide\n",
      "lasts\n",
      "ar e\n",
      "better\n",
      "for\n",
      "wider\n",
      "f eet.' metadata={'source': 'data/Ski_Boots_TDBootz_Special.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents() # Call the function\n",
    "# Inspect the contents of the first document as well as metadata\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 300\n",
    "chunk_overlap=100 # Overlap between consecutive chunks\n",
    "\n",
    "def split_text(documents: list[Document]):\n",
    "  \"\"\"\n",
    "  Split the text content of the given list of Document objects into smaller chunks.\n",
    "  Args:\n",
    "    documents (list[Document]): List of Document objects containing text content to split.\n",
    "  Returns:\n",
    "    list[Document]: List of Document objects representing the split text chunks.\n",
    "  \"\"\"\n",
    "  # Initialize text splitter with specified parameters\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, # Size of each chunk in characters\n",
    "    chunk_overlap=chunk_overlap, # Overlap between consecutive chunks\n",
    "    length_function=len, # Function to compute the length of the text\n",
    "    add_start_index=True, # Flag to add start index to each chunk\n",
    "  )\n",
    "\n",
    "  # Split documents into smaller chunks using text splitter\n",
    "  chunks = text_splitter.split_documents(documents)\n",
    "  print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "  # Print example of page content and metadata for a chunk\n",
    "  document = chunks[0]\n",
    "  print(document.page_content)\n",
    "  print(document.metadata)\n",
    "\n",
    "  return chunks # Return the list of split text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_chroma(chunks: list[Document]):\n",
    "  \"\"\"\n",
    "  Save the given list of Document objects to a Chroma database.\n",
    "  Args:\n",
    "  chunks (list[Document]): List of Document objects representing text chunks to save.\n",
    "  Returns:\n",
    "  None\n",
    "  \"\"\"\n",
    "\n",
    "  # Create a new Chroma database from the documents using OpenAI embeddings\n",
    "  db = Chroma.from_documents(\n",
    "    chunks,\n",
    "    OpenAIEmbeddings(),\n",
    "    client=chroma_client,\n",
    "  )\n",
    "\n",
    "  # Persist the database to disk\n",
    "  # db.persist() # TODO: Delete this line\n",
    "  print(f\"Saved {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 15 documents into 139 chunks.\n",
      "Ski\n",
      "Boots\n",
      "TDBootz\n",
      "Special\n",
      "This\n",
      "guide\n",
      "explains\n",
      "the\n",
      "special\n",
      "consider ation\n",
      "for\n",
      "choosing\n",
      "TDBootz\n",
      "Special\n",
      "Ski\n",
      "boots.\n",
      "1.\n",
      "Understanding\n",
      "Ski\n",
      "Boot\n",
      "Components:\n",
      "Befor e\n",
      "delving\n",
      "int o\n",
      "selecting\n",
      "ski\n",
      "boots,\n",
      "it' s\n",
      "essential\n",
      "t o\n",
      "understand\n",
      "the\n",
      "v arious\n",
      "components\n",
      "that\n",
      "mak e\n",
      "up\n",
      "a\n",
      "ski\n",
      "boot:\n",
      "●\n",
      "Shell:\n",
      "The\n",
      "outer\n",
      "body\n",
      "{'source': 'data/Ski_Boots_TDBootz_Special.pdf', 'page': 0, 'start_index': 0}\n",
      "Saved 139 chunks to chroma.\n"
     ]
    }
   ],
   "source": [
    "def generate_data_store():\n",
    "  \"\"\"\n",
    "  Function to generate vector database in chroma from documents.\n",
    "  \"\"\"\n",
    "  documents = load_documents() # Load documents from a source\n",
    "  chunks = split_text(documents) # Split documents into manageable chunks\n",
    "  save_to_chroma(chunks) # Save the processed data to a data store\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv(override=True)\n",
    "# Generate the data store\n",
    "generate_data_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"List the steps to assemble a bike.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    " - -\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Unbox the bike and lay out all the components.\n",
      "2. Attach the front wheel to the fork, ensuring it is securely fastened with the provided axle and nut.\n",
      "3. Adjust the handlebar height.\n",
      "4. Carefully unpack all components to ensure nothing is damaged.\n",
      "5. Attach the handlebars to the stem and tighten the bolts securely.\n",
      "6. Install the front wheel, ensuring it is centered and secured with quick-release or axle nuts.\n",
      "7. Adjust the seat and maintain your bike.\n"
     ]
    }
   ],
   "source": [
    "def query_rag(query_text, base_url: str = None):\n",
    "  \"\"\"\n",
    "  Query a Retrieval-Augmented Generation (RAG) system using Chroma database and OpenAI.\n",
    "  Args:\n",
    "    - query_text (str): The text to query the RAG system with.\n",
    "  Returns:\n",
    "    - formatted_response (str): Formatted response including the generated text and sources.\n",
    "    - response_text (str): The generated response text.\n",
    "  \"\"\"\n",
    "\n",
    "  test_dic = {\"ss\": \"dd\"}\n",
    "  # YOU MUST - Use same embedding function as before\n",
    "  embedding_function = OpenAIEmbeddings(base_url=base_url, api_key='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')\n",
    "\n",
    "  # Prepare the database\n",
    "  db = Chroma(client=chroma_client, embedding_function=embedding_function)\n",
    "  \n",
    "  # Retrieving the context from the DB using similarity search\n",
    "  results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "\n",
    "  # Check if there are any matching results or if the relevance score is too low\n",
    "  if len(results) == 0 or results[0][1] < 0.7:\n",
    "    print(f\"Unable to find matching results.\")\n",
    "\n",
    "  # Combine context from matching documents\n",
    "  context_text = \"\\n\\n - -\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    " \n",
    "  # Create prompt template using context and query text\n",
    "  prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "  prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "  \n",
    "  # Initialize OpenAI chat model\n",
    "  model = ChatOpenAI()\n",
    "\n",
    "  # Generate response text based on the prompt\n",
    "  response_text = model.predict(prompt)\n",
    " \n",
    "   # Get sources of the matching documents\n",
    "  sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    " \n",
    "  # Format and return response including generated text and sources\n",
    "  formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "  return formatted_response, response_text\n",
    "\n",
    "# Let's call our function we have defined\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "# and finally, inspect our final response!\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
